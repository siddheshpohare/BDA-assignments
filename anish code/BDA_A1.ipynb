{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "029dcBx_JWVj",
        "outputId": "0362bb0d-be56-4f72-a41d-668ac69e284e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== Descriptive Statistics ===\n",
            "+-------+------------------+-------------------+------------------+------------------+\n",
            "|summary|      sepal_length|        sepal_width|      petal_length|       petal_width|\n",
            "+-------+------------------+-------------------+------------------+------------------+\n",
            "|  count|               150|                150|               150|               150|\n",
            "|   mean| 5.843333333333335| 3.0540000000000007|3.7586666666666693|1.1986666666666672|\n",
            "| stddev|0.8280661279778637|0.43359431136217375| 1.764420419952262|0.7631607417008414|\n",
            "|    min|               4.3|                2.0|               1.0|               0.1|\n",
            "|    max|               7.9|                4.4|               6.9|               2.5|\n",
            "+-------+------------------+-------------------+------------------+------------------+\n",
            "\n",
            "=== Correlation Matrix ===\n",
            "DenseMatrix([[ 1.        , -0.10936925,  0.87175416,  0.81795363],\n",
            "             [-0.10936925,  1.        , -0.4205161 , -0.35654409],\n",
            "             [ 0.87175416, -0.4205161 ,  1.        ,  0.9627571 ],\n",
            "             [ 0.81795363, -0.35654409,  0.9627571 ,  1.        ]])\n",
            "=== PCA Result (first 5 rows) ===\n",
            "+-----------------------------------------+\n",
            "|pca_features                             |\n",
            "+-----------------------------------------+\n",
            "|[-2.827135972679026,-5.641331045573357]  |\n",
            "|[-2.7959524821488433,-5.1451668832529425]|\n",
            "|[-2.6215235581650576,-5.177378121203941] |\n",
            "|[-2.7649059004742393,-5.003599415056977] |\n",
            "|[-2.7827501159516594,-5.648648294377423] |\n",
            "+-----------------------------------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from pyspark.sql import SparkSession\n",
        "from pyspark.ml.feature import VectorAssembler, PCA\n",
        "from pyspark.ml.stat import Correlation\n",
        "\n",
        "# Step 1: Create Spark session\n",
        "spark = SparkSession.builder.appName(\"IrisMultivariateAnalysis\").getOrCreate()\n",
        "\n",
        "# Step 2: Load Iris dataset (with real column names)\n",
        "df = spark.read.csv(\"Iris.csv\", header=True, inferSchema=True)\n",
        "\n",
        "# Step 3: Rename columns to standard format\n",
        "df_renamed = df.selectExpr(\n",
        "    \"SepalLengthCm as sepal_length\",\n",
        "    \"SepalWidthCm as sepal_width\",\n",
        "    \"PetalLengthCm as petal_length\",\n",
        "    \"PetalWidthCm as petal_width\",\n",
        "    \"Species as species\"\n",
        ")\n",
        "\n",
        "# Step 4: Assemble features into a vector\n",
        "feature_cols = ['sepal_length', 'sepal_width', 'petal_length', 'petal_width']\n",
        "assembler = VectorAssembler(inputCols=feature_cols, outputCol=\"features\")\n",
        "df_vector = assembler.transform(df_renamed)\n",
        "\n",
        "# Step 5: Descriptive Stats\n",
        "print(\"=== Descriptive Statistics ===\")\n",
        "df_vector.select(feature_cols).describe().show()\n",
        "\n",
        "# Step 6: Correlation Matrix\n",
        "print(\"=== Correlation Matrix ===\")\n",
        "correlation_matrix = Correlation.corr(df_vector, \"features\").head()[0]\n",
        "print(correlation_matrix)\n",
        "\n",
        "# Step 7: PCA\n",
        "pca = PCA(k=2, inputCol=\"features\", outputCol=\"pca_features\")\n",
        "pca_model = pca.fit(df_vector)\n",
        "df_pca = pca_model.transform(df_vector)\n",
        "\n",
        "print(\"=== PCA Result (first 5 rows) ===\")\n",
        "df_pca.select(\"pca_features\").show(5, truncate=False)\n",
        "\n",
        "# Step 8: Stop Spark session\n",
        "spark.stop()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Viva-Ready Explanation of Multivariate Analysis\n",
        "Method\tDescription\n",
        "Descriptive Stats\tShows mean, stddev, min, max for each variable\n",
        "Correlation Matrix\tMeasures linear relationship between features (1 = strong positive, -1 = strong negative)\n",
        "PCA\tReduces dimensionality while retaining max variance; useful for visualizations & reducing computation\n",
        "üìå Sample iris.csv Format (you can use this in Colab or HDFS):\n",
        "\n",
        "sepal_length,sepal_width,petal_length,petal_width,species\n",
        "5.1,3.5,1.4,0.2,setosa\n",
        "4.9,3.0,1.4,0.2,setosa\n",
        "6.2,3.4,5.4,2.3,virginica\n",
        "...\n",
        "\n",
        "üöÄ What Makes This ‚ÄúBig Data‚Äù?\n",
        "\n",
        "    Spark: Can handle large versions of Iris-like datasets distributed across a cluster.\n",
        "\n",
        "    Scalable: You can scale it to millions of rows using the same code.\n",
        "\n",
        "    Parallel: Multivariate stats and PCA are run in parallel across nodes."
      ],
      "metadata": {
        "id": "GRIajDZ1JzPs"
      }
    }
  ]
}