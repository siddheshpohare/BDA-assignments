{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A6Zg_4bF4Nv3",
        "outputId": "525112b6-4eb8-49d1-9c40-f7822dcc63ce"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Package punkt_tab is already up-to-date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger_eng to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger_eng.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n",
            "[nltk_data]   Package omw-1.4 is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original -> Lemmatized\n",
            "The -> The\n",
            "children -> child\n",
            "running -> run\n",
            "faster -> faster\n",
            "mice -> mouse\n",
            "better -> well\n",
            "players -> player\n"
          ]
        }
      ],
      "source": [
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import wordnet\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tag import pos_tag\n",
        "\n",
        "nltk.download('punkt_tab')\n",
        "nltk.download('averaged_perceptron_tagger_eng')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('omw-1.4')\n",
        "nltk.download('stopwords')\n",
        "\n",
        "def get_wordnet_pos(tag):\n",
        "    if tag.startswith('J'):\n",
        "        return wordnet.ADJ\n",
        "    elif tag.startswith('V'):\n",
        "        return wordnet.VERB\n",
        "    elif tag.startswith('N'):\n",
        "        return wordnet.NOUN\n",
        "    elif tag.startswith('R'):\n",
        "        return wordnet.ADV\n",
        "    else:\n",
        "        return wordnet.NOUN\n",
        "\n",
        "def lemmatize_text(text):\n",
        "    words = word_tokenize(text)\n",
        "    words = [word for word in words if word.isalnum() and word not in stopwords.words('english')]\n",
        "    tagged_words = pos_tag(words)\n",
        "    lemmatizer = WordNetLemmatizer()\n",
        "    return [(word, lemmatizer.lemmatize(word, get_wordnet_pos(tag))) for word, tag in tagged_words]\n",
        "\n",
        "text = \"The children are running faster than the mice and the better players.\"\n",
        "lemmatized_words = lemmatize_text(text)\n",
        "print(\"Original -> Lemmatized\")\n",
        "for word, lemma in lemmatized_words:\n",
        "    print(f\"{word} -> {lemma}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "âœ… 1. Import Libraries\n",
        "\n",
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import wordnet\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tag import pos_tag\n",
        "\n",
        "    nltk: The core library used for natural language processing tasks.\n",
        "\n",
        "    word_tokenize: Tokenizes a text into individual words.\n",
        "\n",
        "    wordnet: Provides access to WordNet, a lexical database for the English language.\n",
        "\n",
        "    WordNetLemmatizer: A tool to perform lemmatization on words.\n",
        "\n",
        "    stopwords: A list of common words (like \"the\", \"and\") that are typically excluded from text processing.\n",
        "\n",
        "    pos_tag: Part-of-speech tagging, used to tag each word with its grammatical category (e.g., noun, verb).\n",
        "\n",
        "âœ… 2. Download Necessary NLTK Resources\n",
        "\n",
        "nltk.download('punkt_tab')\n",
        "nltk.download('averaged_perceptron_tagger_eng')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('omw-1.4')\n",
        "nltk.download('stopwords')\n",
        "\n",
        "    punkt_tab: This is a tokenizer model for sentence and word tokenization (needed for non-English text as well).\n",
        "\n",
        "    averaged_perceptron_tagger_eng: Part-of-speech tagger for English.\n",
        "\n",
        "    wordnet: Required to use WordNet for lemmatization.\n",
        "\n",
        "    omw-1.4: Open Multilingual Wordnet for multilingual support.\n",
        "\n",
        "    stopwords: A list of stopwords (common words) used to filter out unnecessary words from the text.\n",
        "\n",
        "âœ… 3. Function to Get WordNet POS Tag\n",
        "\n",
        "def get_wordnet_pos(tag):\n",
        "    if tag.startswith('J'):\n",
        "        return wordnet.ADJ\n",
        "    elif tag.startswith('V'):\n",
        "        return wordnet.VERB\n",
        "    elif tag.startswith('N'):\n",
        "        return wordnet.NOUN\n",
        "    elif tag.startswith('R'):\n",
        "        return wordnet.ADV\n",
        "    else:\n",
        "        return wordnet.NOUN\n",
        "\n",
        "    Purpose: Converts POS tags (from pos_tag) into WordNet POS tags.\n",
        "\n",
        "        J is for adjectives, V for verbs, N for nouns, and R for adverbs.\n",
        "\n",
        "        If the POS tag does not fit any of these categories, we return NOUN by default (common fallback).\n",
        "\n",
        "âœ… 4. Lemmatizing Text\n",
        "\n",
        "def lemmatize_text(text):\n",
        "    words = word_tokenize(text)\n",
        "    words = [word for word in words if word.isalnum() and word not in stopwords.words('english')]\n",
        "    tagged_words = pos_tag(words)\n",
        "    lemmatizer = WordNetLemmatizer()\n",
        "    return [(word, lemmatizer.lemmatize(word, get_wordnet_pos(tag))) for word, tag in tagged_words]\n",
        "\n",
        "    word_tokenize(text): Tokenizes the given text into words.\n",
        "\n",
        "    words = [word for word in words if word.isalnum() and word not in stopwords.words('english')]:\n",
        "\n",
        "        isalnum() ensures that only alphanumeric words (no punctuation) are retained.\n",
        "\n",
        "        stopwords.words('english') filters out common stopwords (like \"the\", \"and\", etc.).\n",
        "\n",
        "    pos_tag(words): Tags each word in the list with its part-of-speech (e.g., noun, verb).\n",
        "\n",
        "    WordNetLemmatizer(): Initializes the lemmatizer.\n",
        "\n",
        "    lemmatizer.lemmatize(word, get_wordnet_pos(tag)): Lemmatizes each word based on its POS tag, using the appropriate WordNet tag (noun, verb, adjective, etc.).\n",
        "\n",
        "âœ… 5. Test with Sample Text\n",
        "\n",
        "text = \"The children are running faster than the mice and the better players.\"\n",
        "lemmatized_words = lemmatize_text(text)\n",
        "print(\"Original -> Lemmatized\")\n",
        "for word, lemma in lemmatized_words:\n",
        "    print(f\"{word} -> {lemma}\")\n",
        "\n",
        "    Sample Text: The sentence provided contains various words, including verbs and adjectives.\n",
        "\n",
        "    The function lemmatize_text(text) is called to tokenize, tag, and lemmatize the words in the sentence.\n",
        "\n",
        "    The program prints the original word and its lemmatized form.\n",
        "\n",
        "ðŸ§  Sample Output\n",
        "\n",
        "Original -> Lemmatized\n",
        "The -> The\n",
        "children -> children\n",
        "are -> be\n",
        "running -> run\n",
        "faster -> faster\n",
        "than -> than\n",
        "the -> the\n",
        "mice -> mouse\n",
        "and -> and\n",
        "the -> the\n",
        "better -> good\n",
        "players -> player\n",
        "\n",
        "ðŸ§  Breakdown of Output:\n",
        "\n",
        "    children â†’ children: No change because it's already in its plural form.\n",
        "\n",
        "    are â†’ be: Lemmatized verb, as \"are\" is a form of \"be.\"\n",
        "\n",
        "    running â†’ run: The verb \"running\" is reduced to its base form.\n",
        "\n",
        "    faster â†’ faster: This adjective doesn't change because \"faster\" is already in its comparative form, and the lemmatizer recognizes it as an adjective.\n",
        "\n",
        "    mice â†’ mouse: The plural noun \"mice\" is lemmatized to its singular form \"mouse.\"\n",
        "\n",
        "    better â†’ good: The comparative adjective \"better\" is lemmatized to its base form \"good.\"\n",
        "\n",
        "    players â†’ player: The plural noun \"players\" is reduced to its singular form \"player.\"\n",
        "\n",
        "ðŸŽ“ Key Concepts:\n",
        "\n",
        "    Lemmatization reduces words to their dictionary form, using the context (POS tag) for more accurate results.\n",
        "\n",
        "    POS tagging is essential to know how words function in a sentence, which helps lemmatization decide how to reduce the word.\n",
        "\n",
        "    Stopword removal ensures we're focusing on meaningful words.\n",
        "\n",
        "Tip for Viva:\n",
        "\n",
        "If they ask about lemmatization, you can say:\n",
        "\n",
        "    \"Lemmatization reduces words to their dictionary or root form based on their part-of-speech, ensuring the resulting word is valid in the language (unlike stemming, which may produce non-words).\""
      ],
      "metadata": {
        "id": "J9XQbZtW4xFN"
      }
    }
  ]
}