{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eo11-iLC2vah",
        "outputId": "a241b45f-645b-45d2-daf9-b766c5b1f070"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Package punkt_tab is already up-to-date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger_eng to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger_eng.zip.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "POS Tags: [('The', 'DT'), ('quick', 'JJ'), ('brown', 'NN'), ('fox', 'NN'), ('jumps', 'VBZ'), ('over', 'IN'), ('the', 'DT'), ('lazy', 'JJ'), ('dog', 'NN'), ('.', '.')]\n"
          ]
        }
      ],
      "source": [
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk import pos_tag\n",
        "\n",
        "# Download required resources\n",
        "nltk.download('punkt_tab')\n",
        "# Download the 'averaged_perceptron_tagger_eng' resource\n",
        "nltk.download('averaged_perceptron_tagger_eng') # This was the missing download\n",
        "\n",
        "\n",
        "# Sample sentence\n",
        "text = \"The quick brown fox jumps over the lazy dog.\"\n",
        "\n",
        "# Tokenize the sentence\n",
        "tokens = word_tokenize(text)\n",
        "\n",
        "# Perform POS tagging\n",
        "tagged = pos_tag(tokens)\n",
        "\n",
        "# Display the tagged output\n",
        "print(\"POS Tags:\", tagged)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "\n",
        "# Load the small English model with word vectors\n",
        "nlp = spacy.load(\"en_core_web_md\")  # Or \"en_core_web_lg\" if installed\n",
        "\n",
        "# Example words\n",
        "word1 = nlp(\"king\")\n",
        "word2 = nlp(\"queen\")\n",
        "word3 = nlp(\"apple\")\n",
        "\n",
        "# Calculate and print similarity\n",
        "print(\"Similarity between king and queen:\", word1.similarity(word2))\n",
        "print(\"Similarity between king and apple:\", word1.similarity(word3))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U8jZdB_s2-KG",
        "outputId": "df23a5a9-8c3e-4f1f-a668-4b2a2b23f2b6"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Similarity between king and queen: 0.38253092765808105\n",
            "Similarity between king and apple: 0.21109060943126678\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python -m spacy download en_core_web_md"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OsHcCKOH3lNo",
        "outputId": "62650d3a-f539-4fb3-c76c-f609114db083"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting en-core-web-md==3.8.0\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_md-3.8.0/en_core_web_md-3.8.0-py3-none-any.whl (33.5 MB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m33.5/33.5 MB\u001b[0m \u001b[31m37.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: en-core-web-md\n",
            "Successfully installed en-core-web-md-3.8.0\n",
            "\u001b[38;5;2m‚úî Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('en_core_web_md')\n",
            "\u001b[38;5;3m‚ö† Restart to reload dependencies\u001b[0m\n",
            "If you are in a Jupyter or Colab notebook, you may need to restart Python in\n",
            "order to load all the package's dependencies. You can do this by selecting the\n",
            "'Restart kernel' or 'Restart runtime' option.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "üîç Explanation for Viva\n",
        "Line\tWhat it Does\n",
        "word_tokenize(text)\tBreaks the sentence into words (tokens).\n",
        "pos_tag(tokens)\tAssigns each word a part-of-speech tag (like noun, verb, adjective, etc.).\n",
        "nltk.download(...)\tDownloads models for tokenization and tagging.\n",
        "tagged\tReturns a list of tuples like [('The', 'DT'), ('fox', 'NN'), ('jumps', 'VBZ')]"
      ],
      "metadata": {
        "id": "xl9vy-AZ34Tt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "üí¨ Explanation for Viva\n",
        "Concept\tDescription\n",
        "Word Embeddings\tRepresent words as high-dimensional vectors capturing semantic meaning.\n",
        "similarity()\tMeasures how similar two words are based on their vector representations.\n",
        "spacy.load(...)\tLoads a model that contains pre-trained word vectors."
      ],
      "metadata": {
        "id": "T3dPzemH35n4"
      }
    }
  ]
}