{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a27b12c8-ebc6-40dc-b1ac-1e847cda9d17",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\ganes\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\ganes\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\ganes\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\ganes\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     C:\\Users\\ganes\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger_eng to\n",
      "[nltk_data]     C:\\Users\\ganes\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger_eng is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter text for lemmatization:  everyone is playing and enjoying the cricket\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Text: everyone is playing and enjoying the cricket\n",
      "Lemmatized Text: everyone be play and enjoy the cricket\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import wordnet\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk import pos_tag, word_tokenize\n",
    "\n",
    "# Download required NLTK resources\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('punkt')\n",
    "nltk.download('punkt_tab')\n",
    "# Download the 'averaged_perceptron_tagger_eng' resource explicitly\n",
    "nltk.download('averaged_perceptron_tagger_eng')\n",
    "\n",
    "# Initialize WordNet Lemmatizer\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "# Function to map POS tags to WordNet format\n",
    "def get_wordnet_pos(tag):\n",
    "    if tag.startswith('J'):\n",
    "        return wordnet.ADJ\n",
    "    elif tag.startswith('V'):\n",
    "        return wordnet.VERB\n",
    "    elif tag.startswith('N'):\n",
    "        return wordnet.NOUN\n",
    "    elif tag.startswith('R'):\n",
    "        return wordnet.ADV\n",
    "    else:\n",
    "        return wordnet.NOUN # Default to noun\n",
    "\n",
    "# Lemmatization function\n",
    "def lemmatize_text(text):\n",
    "    tokens = word_tokenize(text)\n",
    "    pos_tags = pos_tag(tokens)\n",
    "    lemmatized_words = [lemmatizer.lemmatize(word, get_wordnet_pos(tag)) for word, tag in pos_tags]\n",
    "    return ' '.join(lemmatized_words)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    text = input(\"Enter text for lemmatization: \")\n",
    "    lemmatized_text = lemmatize_text(text)\n",
    "    print(f\"Original Text: {text}\")\n",
    "    print(f\"Lemmatized Text: {lemmatized_text}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c339eec-25de-4624-86f3-94ab6518ef5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''‚úÖ What the Code Does (Summary)\n",
    "This Python script performs lemmatization using NLTK‚Äôs WordNetLemmatizer. It:\n",
    "\n",
    "Tokenizes the input sentence\n",
    "\n",
    "Tags each token with its Part-of-Speech (POS)\n",
    "\n",
    "Maps POS tags to a format suitable for WordNet\n",
    "\n",
    "Applies lemmatization to each word\n",
    "\n",
    "Returns the lemmatized text\n",
    "\n",
    "üìö Dataset / Model Used\n",
    "WordNet: A lexical database for English that provides synonyms, antonyms, and base forms (lemmas) of words.\n",
    "\n",
    "POS tagging is done using the averaged_perceptron_tagger from NLTK.\n",
    "\n",
    "üå± What is Lemmatization?\n",
    "Lemmatization is the process of reducing a word to its base or dictionary form (called a lemma), considering the context and part of speech.\n",
    "\n",
    "Example:\n",
    "\n",
    "\"running\" ‚Üí \"run\"\n",
    "\n",
    "\"better\" ‚Üí \"good\"\n",
    "\n",
    "Compared to stemming:\n",
    "\n",
    "Lemmatization is more accurate but slower.\n",
    "\n",
    "It uses a vocabulary and grammar rules (via WordNet).\n",
    "\n",
    "Stemming uses simple rule-based chopping (e.g., PorterStemmer).\n",
    "\n",
    "üì¶ NLTK Resources Used\n",
    "python\n",
    "Copy\n",
    "Edit\n",
    "nltk.download('wordnet')                   # WordNet dictionary for lemmas\n",
    "nltk.download('omw-1.4')                   # Open Multilingual WordNet\n",
    "nltk.download('averaged_perceptron_tagger')# POS tagging\n",
    "nltk.download('punkt')                     # Tokenizer\n",
    "Note: punkt_tab and averaged_perceptron_tagger_eng are unnecessary‚Äîcould be removed.\n",
    "\n",
    "üß† Viva Questions & Answers\n",
    "‚ùì Q1. What is lemmatization?\n",
    "A:\n",
    "Lemmatization reduces words to their base (lemma) form using a vocabulary (WordNet) and POS tags to ensure the transformation respects grammar.\n",
    "\n",
    "‚ùì Q2. Why is POS tagging important in lemmatization?\n",
    "A:\n",
    "Lemmatization needs to know the correct POS to find the accurate lemma.\n",
    "\n",
    "\"running\" as a verb ‚Üí \"run\"\n",
    "\n",
    "\"running\" as a noun ‚Üí stays \"running\"\n",
    "\n",
    "‚ùì Q3. How does your code map POS tags?\n",
    "A:\n",
    "It uses the get_wordnet_pos() function to convert tags from pos_tag() into the format expected by WordNetLemmatizer.\n",
    "\n",
    "‚ùì Q4. What would happen if you didn't map POS tags?\n",
    "A:\n",
    "The lemmatizer would assume all words are nouns, possibly giving incorrect results.\n",
    "\n",
    "‚ùì Q5. Example of lemmatization with and without POS tag?\n",
    "A:\n",
    "\n",
    "python\n",
    "Copy\n",
    "Edit\n",
    "lemmatizer.lemmatize(\"running\")        # run (assumes noun)\n",
    "lemmatizer.lemmatize(\"running\", 'v')   # run\n",
    "‚ùì Q6. What‚Äôs the difference between stemmer.stem() and lemmatizer.lemmatize()?\n",
    "A:\n",
    "\n",
    "Stemmer: Rule-based, may produce non-words (e.g., ‚Äústudies‚Äù ‚Üí ‚Äústudi‚Äù)\n",
    "\n",
    "Lemmatizer: Uses dictionary, returns real words (e.g., ‚Äústudies‚Äù ‚Üí ‚Äústudy‚Äù)\n",
    "\n",
    "‚ùì Q7. Can lemmatization handle irregular words?\n",
    "A:\n",
    "Yes, WordNet includes irregular forms.\n",
    "Example: \"better\" ‚Üí \"good\"\n",
    "\n",
    "‚ùì Q8. Why did you choose NLTK over spaCy?\n",
    "A:\n",
    "NLTK offers:\n",
    "\n",
    "Detailed control over lemmatization\n",
    "\n",
    "Integration with WordNet\n",
    "\n",
    "Explicit POS mapping\n",
    "\n",
    "spaCy is faster and easier for pipeline tasks but less transparent in control.\n",
    "\n",
    "‚ùì Q9. What are limitations of this code?\n",
    "A:\n",
    "\n",
    "Doesn't remove stopwords or punctuation\n",
    "\n",
    "No error handling for blank input\n",
    "\n",
    "Depends on English language (WordNet)'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
